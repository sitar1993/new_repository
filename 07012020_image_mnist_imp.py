# -*- coding: utf-8 -*-
"""07012020- image_mnist_imp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CIws9kmS0d86N9PgIQLP-g_PtdNNJZDA
"""

# Commented out IPython magic to ensure Python compatibility.
import keras
# %tensorflow_version 1.x

from keras.datasets import mnist

import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import random

from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam, RMSprop
from keras.utils.np_utils import to_categorical

(x_train, y_train), (x_test, y_test) = mnist.load_data()

print('no of tainnig images = ',x_train.shape[0])
print('no of tainnig labels = ',y_train.shape[0])

print('w X h of tainnig images = ',x_train.shape[1:])
print('w X h of testing images = ',x_test.shape[1:])

print('\ntraining_input___________________________: x_train.shape = ', x_train.shape)
print('labels___________________________________: y_train.shape = ', y_train.shape)

plt.imshow(x_train[0])
plt.title(y_train[0])
plt.show()

plt.imshow(x_train[39])
plt.title(y_train[39])
plt.show()

plt.imshow(x_train[84])
plt.title(y_train[84])
plt.show()

plt.imshow(x_train[104])
plt.title(y_train[104])
plt.show()

sumnum = 0
for i in range(10):
  sumnum += len(y_train[y_train == i])
  print(i, '------>', len(y_train[y_train == i]))
print('total = ',sumnum)

sns.countplot(y_train)
plt.show()

n_cols = 5
n_classes = 10
fig, axes = plt.subplots(n_classes, n_cols,  figsize=(5, 10))
#fig.tight_layout()
axes[2,1].imshow(x_train[3]) # this will draw the image in 2nd row and 1st column
plt.show()

n_classes = 10
n_cols = 5
fig, ax = plt.subplots(nrows=n_classes, ncols=n_cols, figsize=(5,8))
fig.tight_layout()

for i in range(n_cols):
  for j in range(n_classes):
    selected_images = x_train[y_train == j] 
    ax[j][i].imshow(selected_images[np.random.randint(0, len(selected_images)-1), :, :])
    ax[j][i].set_title(y_train[y_train == j][j])
    ax[j][i].axis('off')

n_cols = 5
n_classes = 10
fig, axes = plt.subplots(n_classes,n_cols, figsize=(5, 10))
fig.tight_layout()


for i in range(n_cols):         # <------------ i varies from 0 to 4 (column wise), bcz n_cols =5
  for j in range(n_classes):    # <------------ j varies from 0 to 9 (row wise), bcz n_classes = 10
    slected_images = x_train[y_train == j]   # <------------ selected_images is an array of same type of images, (from x_train but at y_train = j)
    image = slected_images[random.randint(0, len(slected_images)-1), :, :]   # < --------image is a single image from selected_images 
    axes[j][i].imshow(image, cmap='gray')  
    axes[j][i].axis('off')
    #axes[j][i].set_title(y_train[image])  #  <-- this cannot show the right title
    #axes[j][i].set_title(str(j)) 
    if i == 2:
      axes[j][i].set_title(str(j))

axes

n_rows = 5 
n_classes = 10  
fig, axes = plt.subplots(n_rows, n_classes, figsize=(10,5))
fig.tight_layout()


for i in range(n_rows):
  for j in range(n_classes):
    slected_images = x_train[y_train == j]  # <-- select x_train but at y_train = j
    image = slected_images[random.randint(0, len(slected_images)-1), :, :]  
    axes[i][j].imshow(image, cmap='gray')  
    axes[i][j].axis('off')
    #axes[i][j].set_title(y_train[image])
    axes[i][j].set_title(str(j))

n_pixels = x_train.shape[1]*x_train.shape[2] 
def preprocess(image):
  image = image.reshape(n_pixels) # <-- to conv the image into 1d array or to flatten the array
  image = image/255  # to convert all the values in pu
  return image

x_train = np.array(list(map(preprocess, x_train)))

x_test = np.array(list(map(preprocess, x_test)))

x_train.shape; x_test.shape

y_train

y_train = to_categorical(y_train, n_classes) # # n_classes = len(np.unique(y_train))

y_test = to_categorical(y_test, n_classes)

print(y_train.shape)
y_train

model = Sequential()
model.add(Dense(units=222, input_dim=n_pixels, activation='sigmoid'))
model.add(Dense(383, activation='sigmoid'))
model.add(Dense(10, activation='softmax'))
model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

h = model.fit(x_train, y_train, epochs=10, verbose=1, validation_data=(x_test, y_test))

plt.plot(h.history['loss'], label='training loss')
plt.plot(h.history['val_loss'], label='testing loss')
plt.legend()
plt.show()

plt.plot(h.history['accuracy'], label='training accuracy')
plt.plot(h.history['val_accuracy'], label='testing accuracy')
plt.legend()
plt.show()

model.save('07012020- mnist_pptron_rmsprop3.h5')
from google.colab import files
files.download('07012020- mnist_pptron_rmsprop3.h5')

