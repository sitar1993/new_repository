# -*- coding: utf-8 -*-
"""10012020- rnd_image_mnist_with_convolution_filter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CHbn4sMST5JV0MrQVfEjWPa0nQg8q2pn
"""

from keras.datasets import mnist

import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
#import random
import cv2

from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.optimizers import Adam, RMSprop
from keras.utils.np_utils import to_categorical

(x_train, y_train), (x_test, y_test) = mnist.load_data()

print('no of trainnig images',x_train.shape[0])
print('no of trainnig labels',y_train.shape[0])

print('w X h of trainnig images',x_train.shape[1:])
print('w X h of testing images',x_test.shape[1:])

print('\ntraining_input___________________________: x_train.shape = ', x_train.shape)
print('labels___________________________________: y_train.shape = ', y_train.shape)

plt.imshow(x_train[104])
plt.title(y_train[104])
plt.show()

n_rows = n_classes = 10  # len(   np.unique(  y_train  )    )  <-- because 'y_train' contains all the classes
n_cols = 5
fig, axes = plt.subplots(n_rows, n_cols, figsize=(5,10) )
fig.tight_layout()

for i in range(n_cols):
  for j in range(n_rows):
    selected_images = x_train[y_train == j]
    num = np.random.randint(0, len(selected_images)-1) # or --> num = random.randint(0, len(selected_images)-1) <-- but you have to import 'random'
    image = selected_images[num] # or --> image = images[num, :, :]
    axes[j][i].imshow(image) 
    axes[j][i].axis('off')
    axes[j][i].set_title(str(j))
plt.show()

images = x_train[y_train == 0]

image = images[999, :, :]

image

cv2.imshow('image', image) 
cv2.waitKey(0)
cv2.destroyAllWindows()

# cv2.imshow() is disabled in Colab, because it causes Jupyter sessions
# to crash; As a substitution, consider using
# from google.colab.patches import cv2_imshow

plt.imshow(image)
plt.show()

images

y_train

n_cols = 5
n_classes = 10
fig, axes = plt.subplots(n_classes,n_cols, figsize=(5, 10))
fig.tight_layout()


for i in range(n_cols):
  for j in range(n_classes):
    slected_images = x_train[y_train == j]  # <-- select x_train but at y_train = j
    image = slected_images[random.randint(0, len(slected_images)-1), :, :]  
    axes[j][i].imshow(image, cmap='gray')  
    axes[j][i].axis('off')
    #axes[j][i].set_title(y_train[image])
    axes[j][i].set_title(str(j))

x_train.shape

y_train.shape # (60000,) check its shape after passing it through 'to_categirical()' as -->  "y_train = to_categorical(y_train, len(np.unique(y_train)))"

y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

y_train.shape  # after applying to_categorical()

x_train = x_train.reshape(x_train.shape[0], 28, 28, 1) # no of elements in x_train = 60k x 28 x 28 x 1 = 47040000
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)

x_train = x_train.reshape(x_train.shape[0], 28, 28, 3)  # ValueError: cannot reshape array of size 47040000 into shape (60000,28,28,3)
                                                        # because 60k x 28 x 28 x 3 = 14,11,20,000  >> 4,70,40,000



x_train;x_train.shape



x_train = x_train/255  # pu conversion
X_test = x_test/255

# CONVOLUTIONAL NEURAL NETWORK

model = Sequential() 

model.add(Conv2D(32, (5,5), input_shape=(28, 28, 1), activation='relu'))  # Conv2D(no_of_filters, size_of_filter, input_shape=(), activation=' '), 
                                                                          # No of parameters(in this layer) = 5*5*32+32 = 832
                                                                          # 5*5 = 25 no of weights of each filter/kernel
                                                                          # 32 = is the no of filters
                                                                          # 32 = no of biases of 32 filters (each filter = one bias)
model.add(MaxPooling2D(pool_size=(2,2) ))

model.add(Conv2D(64, (3,3), activation='relu'))  # 2nd time no need of 'input_shape=()'
model.add(MaxPooling2D(pool_size=(2,2) ))

model.add(Flatten())
model.add(Dense(256, activation='relu'))  # no need to mention arg 'input_dim= ___ ' within Dense() when convolution is aded in model
#model.add(Dense(387, activation='relu'))
model.add(Dense(10, activation='softmax')) 
model.compile(RMSprop(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

h = model.fit(x_train, y_train, epochs=10, verbose=1, validation_data=(x_test, y_test))

# at 98.29% accuracy
plt.plot(h.history['loss'], label='training loss')
plt.plot(h.history['val_loss'], label='testing loss')
plt.legend()
plt.show()

plt.plot(h.history['acc'], label='training accuracy')
plt.plot(h.history['val_acc'], label='testing accuracy')
plt.legend()
plt.show()

# at 87% accuracy
plt.plot(h.history['loss'], label='training loss')
plt.plot(h.history['val_loss'], label='testing loss')
plt.legend()
plt.show()

plt.plot(h.history['acc'], label='training accuracy')
plt.plot(h.history['val_acc'], label='testing accuracy')
plt.legend()
plt.show()

















####################################################################################################################################################
#############################################################################################################################